{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from somefunctions import *\n",
    "from f1_score import *\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "pool_size = (2, 2)\n",
    "train_shape = 400 #size of the training images\n",
    "patch_size = 16\n",
    "input_size = 64\n",
    "pad_size = int(input_size/2 - patch_size/2)\n",
    "pad_rotate_size = int( input_size / np.sqrt(2) ) + 2\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "reg = 1e-5  #regularization term\n",
    "learning_rate = 0.001\n",
    "nb_epoch = 45 #very small, only preliminary tests\n",
    "batch_size = 250\n",
    "steps_per_epoch = 125 #the number of training samples is huge, arbitrary value\n",
    "\n",
    "\n",
    "# Data augmentation parameters\n",
    "FLIP_FLAG = True # add random flips to the patches\n",
    "ROTATION_FLAG = True # add random rotation to the patches\n",
    "BRIGHT_CONTRAST_FLAG = True # modify randomly the brightness and the constrast\n",
    "\n",
    "\n",
    "#Other stuff\n",
    "NameWeights = 'NicolaWeights'\n",
    "SubmissionName = 'NicolaSubmission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(X):\n",
    "    '''Data augmentation on X, element of size (input_size * input_size * 3)'''\n",
    "    #flip\n",
    "    if FLIP_FLAG:\n",
    "        flip_decision = np.random.choice(3)\n",
    "        if flip_decision == 1:\n",
    "            X = np.flipud(X)\n",
    "        if flip_decision == 2: \n",
    "            X = np.fliplr(X)\n",
    "    \n",
    "    #contrast and brightness\n",
    "    if BRIGHT_CONTRAST_FLAG:\n",
    "        brightness = np.random.rand()*0.3 - 0.15\n",
    "        contrast = np.random.rand()*0.25 - 0.125\n",
    "        X = np.clip( X * (contrast/0.5+1) - contrast + brightness, 0, 1)\n",
    "        \n",
    "    return X\n",
    "\n",
    "def crop_center(img,cropx,cropy):\n",
    "    if len(img.shape) == 3:\n",
    "        y,x, _ = img.shape\n",
    "    if len(img.shape) == 2:\n",
    "        y,x = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)    \n",
    "    return img[starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "def generate_minibatch_with_arbitrary_rotation(X,Y):\n",
    "    \"\"\"\n",
    "    Generate a minibatch\n",
    "    \"\"\"\n",
    "    while 1:        \n",
    "        # Generate one minibatch\n",
    "        X_batch = np.empty((batch_size, input_size, input_size, 3))\n",
    "        Y_batch = np.empty(batch_size)\n",
    "        low=pad_rotate_size + patch_size // 2\n",
    "        high = pad_rotate_size + train_shape - patch_size // 2\n",
    "        for i in range(batch_size):\n",
    "            # Select a random image\n",
    "            idx = np.random.choice(X.shape[0])\n",
    "            \n",
    "            x_coord = np.random.randint(low=low, high = high ) \n",
    "            y_coord = np.random.randint(low=low, high = high )\n",
    "            \n",
    "            X_temp = X[idx,x_coord - pad_rotate_size:x_coord + pad_rotate_size,\n",
    "                           y_coord - pad_rotate_size:y_coord + pad_rotate_size]\n",
    "            \n",
    "            #arbitrary rotation and crop of X_temp\n",
    "            degree = np.random.choice(180)\n",
    "            X_temp = scipy.ndimage.interpolation.rotate(X_temp, degree)\n",
    "            X_temp = crop_center(X_temp,input_size,input_size)\n",
    "            \n",
    "            X_temp = data_augmentation(X_temp)\n",
    "            \n",
    "            X_batch[i] = X_temp\n",
    "            \n",
    "            gt_temp = Y[idx,x_coord - pad_rotate_size:x_coord + pad_rotate_size,\n",
    "                            y_coord - pad_rotate_size:y_coord + pad_rotate_size]  #TODO: reduce this crop size\n",
    "            \n",
    "            #arbitrary rotation and crop of gt_temp\n",
    "            #same degree\n",
    "            gt_temp = scipy.ndimage.interpolation.rotate(gt_temp, degree)\n",
    "            gt_temp = crop_center(gt_temp,patch_size,patch_size)\n",
    "            Y_batch[i] = patch_to_label(gt_temp)\n",
    "            \n",
    "        yield X_batch, Y_batch\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    '''Create a sequential model'''        \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Convolution2D(64, (5,5), \n",
    "                            input_shape = ( input_size, input_size, 3),\n",
    "                            padding = 'SAME', activation = 'relu',\n",
    "                            kernel_initializer = K_init.RandomUniform(minval=-0.05, maxval=0.05, seed=1)\n",
    "                           ))\n",
    "    \n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(64, (3,3), \n",
    "                            input_shape = ( input_size, input_size, 3),\n",
    "                            padding = 'SAME', activation = 'relu',\n",
    "                            kernel_initializer = K_init.RandomUniform(minval=-0.05, maxval=0.05, seed=1)\n",
    "                           ))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(128, (3,3),\n",
    "                            padding = 'SAME', activation = 'relu',\n",
    "                            kernel_initializer = K_init.RandomUniform(minval=-0.05, maxval=0.05, seed=1)\n",
    "                           ))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(256, (3,3),\n",
    "                            padding = 'SAME', activation = 'relu',\n",
    "                            kernel_initializer = K_init.RandomUniform(minval=-0.05, maxval=0.05, seed=1)\n",
    "                           ))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation = 'relu', kernel_regularizer = l2(reg)))\n",
    "    model.add(Dropout(0.5))         \n",
    "    model.add(Dense(256, activation = 'relu', kernel_regularizer = l2(reg)))\n",
    "    model.add(Dropout(0.5))       \n",
    "    model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "    #Optimizer          \n",
    "    opt = Adam(lr=learning_rate) # Adam optimizer with default initial learning rate\n",
    " \n",
    "\n",
    "    # This callback reduces the learning rate when the training accuracy does not improve any more\n",
    "    lr_callback = ReduceLROnPlateau(monitor='acc', factor=0.5, patience=5,\n",
    "                                    verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "    \n",
    "    # Stops the training process upon convergence\n",
    "    stop_callback = EarlyStopping(monitor='acc', min_delta=0.0001, patience=10, verbose=1, mode='auto')\n",
    "    \n",
    "    model.compile(loss=binary_crossentropy,\n",
    "                  optimizer=opt,\n",
    "                  metrics=['acc', f1_score])\n",
    "    \n",
    "    return model, stop_callback, lr_callback\n",
    "\n",
    "    \n",
    "\n",
    "def train(X, Y):    \n",
    "    '''\n",
    "    Generate an instance of the model an train the model on X, Y\n",
    "    '''\n",
    "    print('Training set shape: ', X.shape) \n",
    "    print(f'Batch_size: {batch_size} \\nSteps per epoch: {steps_per_epoch} \\n')\n",
    "    \n",
    "    \n",
    "    model, stop_callback, lr_callback = create_model()\n",
    "    \n",
    "    np.random.seed(20122018) # Reproducibility + remember the deadline is the 20.12.2018\n",
    "    \n",
    "    try:\n",
    "        model.fit_generator(generate_minibatch_with_arbitrary_rotation(X,Y),\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            verbose=1,\n",
    "                            callbacks=[lr_callback, stop_callback])\n",
    "    except KeyboardInterrupt:\n",
    "        print('\\n\\nKeyboard interruption!\\n\\n')\n",
    "        pass\n",
    "    \n",
    "\n",
    "    model.save_weights(NameWeights)\n",
    "    \n",
    "    print(f'Training completed, weights saved in: {NameWeights}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "satImage_001.png\n",
      "Loading 100 images\n",
      "satImage_001.png\n"
     ]
    }
   ],
   "source": [
    "# Load a set of image\n",
    "root_dir = \"../Data/training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = len(files) \n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs_original = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "gt_imgs_not_padded = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "print(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 494, 494, 3)\n",
      "(100, 494, 494)\n"
     ]
    }
   ],
   "source": [
    "imgs = padding_imgs(np.array(imgs),pad_rotate_size)\n",
    "gt_imgs = padding_GT(np.array(gt_imgs),pad_rotate_size)\n",
    "print(imgs.shape)\n",
    "print(gt_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (100, 494, 494, 3)\n",
      "Batch_size: 250 \n",
      "Steps per epoch: 125 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\nicol\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:75: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=125, verbose=1, callbacks=[<keras.ca..., epochs=45)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      " 15/125 [==>...........................] - ETA: 9:48 - loss: 0.6892 - acc: 0.7355 - f1_score: 0.0169\n",
      "\n",
      "Keyboard interruption!\n",
      "\n",
      "\n",
      "Training completed, weights saved in: NicolaWeights\n"
     ]
    }
   ],
   "source": [
    "model = train(imgs,gt_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62500, 64, 64, 3)\n",
      "(625, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "IDX = 1\n",
    "X = imgs_to_windows(imgs,400,patch_size,input_size)\n",
    "patches_idx = X[625*IDX:625*(IDX+1)]\n",
    "\n",
    "print(X.shape)\n",
    "print(patches_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20874691]\n",
      " [0.20507324]\n",
      " [0.20845413]]\n"
     ]
    }
   ],
   "source": [
    "Z_idx = model.predict(patches_idx)\n",
    "labels_idx = (Z_idx > 0.5) *1 \n",
    "print(Z_idx[:3])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
