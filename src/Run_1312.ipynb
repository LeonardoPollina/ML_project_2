{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'py_files')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHOOSE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model_3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and pad images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a set of image\n",
    "root_dir = \"../Data/training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = len(files) \n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs_original = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "gt_imgs_not_padded = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "\n",
    "print('Padding images using pad of: ', pad_rotate_size)\n",
    "imgs = padding_imgs(np.array(imgs),pad_rotate_size)\n",
    "gt_imgs = padding_GT(np.array(gt_imgs),pad_rotate_size)\n",
    "print(imgs.shape)\n",
    "print(gt_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split in validation + train: TODO, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imgs\n",
    "Y_train = gt_imgs\n",
    "model = train(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if we want to go on with the training ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = imgs\n",
    "# Y_train = gt_imgs\n",
    "# model, lr_callback, stop_callback = create_model()\n",
    "# model.load_weights('NicolaWeights0612')\n",
    "\n",
    "# np.random.seed(3) # We don't want to take the same data\n",
    "    \n",
    "# try:\n",
    "#     model.fit_generator(generate_minibatch(X_train,Y_train),\n",
    "#                             steps_per_epoch=steps_per_epoch,\n",
    "#                             nb_epoch=3,\n",
    "#                             verbose=1,\n",
    "#                             callbacks=[lr_callback, stop_callback])\n",
    "# except KeyboardInterrupt:\n",
    "#     print('\\n\\nKeyboard interruption!\\n\\n')\n",
    "#     pass\n",
    "# model.save_weights('NicolaWeights2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 1\n",
    "imgs = padding_imgs(np.array(imgs_original),pad_size)\n",
    "X = imgs_to_windows(imgs[:2],400,patch_size,input_size)\n",
    "patches_idx = X[625*IDX:625*(IDX+1)]\n",
    "Z_idx = model.predict(patches_idx)\n",
    "labels_idx = (Z_idx[:,0] < Z_idx[:,1]) * 1 \n",
    "predicted_image = label_to_img(400,400,16,16,labels_idx)\n",
    "temp = concatenate_images(imgs_original[IDX],predicted_image)\n",
    "plt.imshow(concatenate_images(temp, gt_imgs_not_padded[IDX]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_valid = 3\n",
    "N = 100\n",
    "X_valid = imgs_original[N-N_valid:]\n",
    "X_valid = padding_imgs(np.array(X_valid),pad_size)\n",
    "#create the input for the model\n",
    "val_inputs = imgs_to_windows(X_valid,400,patch_size,input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the true value of the labels\n",
    "Y_valid = gt_imgs_not_padded[N-N_valid:]\n",
    "val_gt_patches = [img_crop(Y_valid[i], patch_size, patch_size) for i in range(N_valid)]\n",
    "val_gt_patches =  np.asarray([val_gt_patches[i][j] for i in range(len(val_gt_patches)) for j in range(len(val_gt_patches[i]))])\n",
    "val_true_labels = np.asarray([value_to_class(np.mean(val_gt_patches[i])) for i in range(len(val_gt_patches))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "val_prediction = model.predict(val_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "val_predicted_labels = ((val_prediction[:,0] < val_prediction[:,1]) * 1 ).flatten()\n",
    "val_accuracy = np.sum(np.abs(val_predicted_labels - val_true_labels))/val_true_labels.shape[0]\n",
    "print('Accuracy on validation set is: ', 1 - val_accuracy)\n",
    "print('F1 score on validation set is:', f1_score(val_true_labels,val_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images and pad them\n",
    "test_images = np.asarray(pick_test_images())\n",
    "\n",
    "test_images = padding_imgs(np.array(test_images),pad_size)\n",
    "\n",
    "test_images_not_padded = np.asarray(pick_test_images())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the input for the prediction\n",
    "test_inputs = imgs_to_windows(test_images,608,patch_size,input_size)\n",
    "print(test_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recover the model\n",
    "model, _,_ = create_model()\n",
    "model.load_weights(NameWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "test_prediction = model.predict(test_inputs)\n",
    "print(test_prediction[0:3])\n",
    "test_predicted_labels = ((test_prediction[:,0] < test_prediction[:,1]) * 1 ).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_predicted_labels.reshape(50,-1)\n",
    "print('Every row contains the labels of one image')\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_masks_to_submission(SubmissionName, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Suppose that we create some patches\n",
    "predicted_patches = test_predicted_labels\n",
    "print('Predicted patches of size: ', predicted_patches.shape)\n",
    "\n",
    "\n",
    "# Choose a name for the objects that we are going to save\n",
    "name = PredictionName\n",
    "\n",
    "# Saving the objects:\n",
    "with open(name, 'wb') as f:\n",
    "    pickle.dump(predicted_patches, f)\n",
    "print('Saved in ', name)\n",
    "\n",
    "# Getting back the objects:\n",
    "with open(name, 'rb') as f: \n",
    "    recovered_patches = pickle.load(f)\n",
    "print('Recovered!')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
