{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from somefunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration parameters\n",
    "Easier if we put them all togheter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "pool_size = (2, 2)\n",
    "train_shape = 400 #size of the training images\n",
    "patch_size = 16\n",
    "input_size = 64\n",
    "pad_size = int(input_size/2 - patch_size/2)\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "reg = 1e-6  #regularization term\n",
    "learning_rate = 0.001\n",
    "nb_epoch = 40 #very small, only preliminary tests\n",
    "batch_size = 128\n",
    "steps_per_epoch = 250 #the number of training samples is huge, arbitrary value\n",
    "\n",
    "\n",
    "# Data augmentation parameters\n",
    "FLIP_FLAG = True # add random flips to the patches\n",
    "ROTATION_FLAG = True # add random rotation to the patches\n",
    "BRIGHT_CONTRAST_FLAG = True # modify randomly the brightness and the constrast\n",
    "\n",
    "\n",
    "#Other stuff\n",
    "NameWeights = 'MarionWeights'\n",
    "SubmissionName = 'MarionSubmission.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to generate the minibatch + data augmentation\n",
    "This function will be called during the training. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(X):\n",
    "    '''Data augmentation on X, element of size (input_size * input_size * 3)'''\n",
    "    #flip\n",
    "    if FLIP_FLAG:\n",
    "        flip_decision = np.random.choice(3)\n",
    "        if flip_decision == 1:\n",
    "            X = np.flipud(X)\n",
    "        if flip_decision == 2: \n",
    "            X = np.fliplr(X)\n",
    "    \n",
    "    #rotate\n",
    "    if ROTATION_FLAG:\n",
    "        number_of_rotations = np.random.choice(3)\n",
    "        X = np.rot90(X, number_of_rotations)\n",
    "    \n",
    "    #contrast and brightness\n",
    "    if BRIGHT_CONTRAST_FLAG:\n",
    "        brightness = np.random.rand()*0.2 - 0.1\n",
    "        contrast = np.random.rand()*0.2 - 0.1\n",
    "        X = np.clip( X * (contrast/0.5+1) - contrast + brightness, 0, 1)\n",
    "        \n",
    "    return X\n",
    "\n",
    "def generate_minibatch(X,Y):\n",
    "    \"\"\"\n",
    "    Generate a minibatch\n",
    "    \"\"\"\n",
    "    while 1:\n",
    "        # Generate one minibatch\n",
    "        X_batch = np.empty((batch_size, input_size, input_size, 3))\n",
    "        Y_batch = np.empty(batch_size)\n",
    "        low=input_size//2\n",
    "        high = (train_shape + 2*pad_size - input_size//2)\n",
    "        for i in range(batch_size):\n",
    "            # Select a random image\n",
    "            idx = np.random.choice(X.shape[0])\n",
    "            \n",
    "            x_coord = np.random.randint(low=low, high = high ) \n",
    "            y_coord = np.random.randint(low=low, high = high )\n",
    "      \n",
    "            X_temp = X[idx,x_coord - input_size//2:x_coord + input_size//2,\n",
    "                           y_coord - input_size//2:y_coord + input_size//2]\n",
    "            X_batch[i] = data_augmentation(X_temp)\n",
    "            \n",
    "            gt_temp = Y[idx,x_coord - patch_size//2:x_coord + patch_size//2,\n",
    "                            y_coord - patch_size//2:y_coord + patch_size//2]            \n",
    "            Y_batch[i] = patch_to_label(gt_temp)\n",
    "            \n",
    "        yield X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "Generate the model and train the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the dropouts with p = 0.5\n",
    "def create_model():\n",
    "    '''Create a sequential model'''        \n",
    "    model = Sequential()\n",
    "    \n",
    "    # BLOCK 1: 2 conv + pooling\n",
    "    model.add(Convolution2D(32, (3,3), \n",
    "                            input_shape = ( input_size, input_size, 3),\n",
    "                            padding = 'SAME' , activation='relu'))\n",
    "    model.add(Convolution2D(32, (3,3),\n",
    "                            padding = 'SAME' , activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # BLOCK 2: 2 conv + pooling\n",
    "    model.add(Convolution2D(64, (3,3), \n",
    "                            input_shape = ( input_size, input_size, 3),\n",
    "                            padding = 'SAME' , activation='relu'))\n",
    "    model.add(Convolution2D(64, (3,3),\n",
    "                            padding = 'SAME' , activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # BLOCK 3: 3 conv + pooling\n",
    "    model.add(Convolution2D(128, (3,3), \n",
    "                            input_shape = ( input_size, input_size, 3),\n",
    "                            padding = 'SAME' , activation='relu'))\n",
    "    model.add(Convolution2D(128, (3,3),\n",
    "                            padding = 'SAME' , activation='relu'))\n",
    "    model.add(Convolution2D(128, (3,3),\n",
    "                            padding = 'SAME' , activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # Skip the BLOCK 4, otherwise the dimensions are shrinked too much, I think\n",
    "\n",
    "    # Final BLOCK\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))         \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))       \n",
    "    model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "    #Optimizer          \n",
    "    opt = Adam(lr=learning_rate) # Adam optimizer with default initial learning rate\n",
    " \n",
    "\n",
    "    # This callback reduces the learning rate when the training accuracy does not improve any more\n",
    "    lr_callback = ReduceLROnPlateau(monitor='acc', factor=0.5, patience=5,\n",
    "                                    verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "    \n",
    "    # Stops the training process upon convergence\n",
    "    stop_callback = EarlyStopping(monitor='acc', min_delta=0.0001, patience=11, verbose=1, mode='auto')\n",
    "    \n",
    "    model.compile(loss=binary_crossentropy,\n",
    "                  optimizer=opt,\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model, stop_callback, lr_callback\n",
    "\n",
    "    \n",
    "\n",
    "def train(X, Y):    \n",
    "    '''\n",
    "    Generate an instance of the model an train the model on X, Y\n",
    "    '''\n",
    "    print('Training set shape: ', X.shape) \n",
    "    print(f'Batch_size: {batch_size} \\nSteps per epoch: {steps_per_epoch} \\n')\n",
    "    \n",
    "    \n",
    "    model, stop_callback, lr_callback = create_model()\n",
    "    \n",
    "    np.random.seed(20122018) # Reproducibility + remember the deadline is the 20.12.2018\n",
    "    \n",
    "    try:\n",
    "        model.fit_generator(generate_minibatch(X,Y),\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            verbose=1,\n",
    "                            callbacks=[lr_callback, stop_callback])\n",
    "    except KeyboardInterrupt:\n",
    "        print('\\n\\nKeyboard interruption!\\n\\n')\n",
    "        pass\n",
    "    \n",
    "\n",
    "    model.save_weights(NameWeights)\n",
    "    \n",
    "    print(f'Training completed, weights saved in: {NameWeights}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a set of image\n",
    "root_dir = \"../Data/training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = len(files) \n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs_original = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "gt_imgs_not_padded = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "print(files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing on the whole images\n",
    "\n",
    "Simply padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = padding_imgs(np.array(imgs),pad_size)\n",
    "gt_imgs = padding_GT(np.array(gt_imgs),pad_size)\n",
    "print(imgs.shape)\n",
    "print(gt_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split in validation + train\n",
    "\n",
    "(VERY BASIC!) In this way we can check directly what happens in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = imgs.shape[0]\n",
    "# ratio = 0.8\n",
    "# N_train = int(N*ratio)\n",
    "# N_valid = int(N - N*ratio)\n",
    "# X_train = imgs[:N_train]\n",
    "# X_valid = imgs[N-N_valid:]\n",
    "# Y_train = gt_imgs[:N_train]\n",
    "# print(X_train.shape)\n",
    "# print(X_valid.shape)\n",
    "# print(X_train.shape[0] + X_valid.shape[0])\n",
    "# model = train(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since it is very slow, our validation is directly crowdAI, skip the validation part...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imgs\n",
    "Y_train = gt_imgs\n",
    "model = train(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if we want to go on with the training ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imgs\n",
    "Y_train = gt_imgs\n",
    "model, lr_callback, stop_callback = create_model()\n",
    "model.load_weights('NicolaWeights0612')\n",
    "\n",
    "np.random.seed(20122018) # Reproducibility + remember the deadline is the 20.12.2018\n",
    "    \n",
    "try:\n",
    "    model.fit_generator(generate_minibatch(X_train,Y_train),\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            nb_epoch=3,\n",
    "                            verbose=1,\n",
    "                            callbacks=[lr_callback, stop_callback])\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n\\nKeyboard interruption!\\n\\n')\n",
    "    pass\n",
    "model.save_weights('NicolaWeights2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if on the train set we have good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 1\n",
    "X = imgs_to_windows(imgs,400,patch_size,input_size)\n",
    "patches_idx = X[625*IDX:625*(IDX+1)]\n",
    "\n",
    "print(X.shape)\n",
    "print(patches_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_idx = model.predict(patches_idx)\n",
    "labels_idx = (Z_idx > 0.5) *1 \n",
    "print(Z_idx[:3])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image = label_to_img(400,400,16,16,labels_idx)\n",
    "temp = concatenate_images(imgs_original[IDX],predicted_image)\n",
    "plt.imshow(concatenate_images(temp, gt_imgs_not_padded[IDX]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check what happens on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recover the weights without training everything again\n",
    "# model,_,_ = create_model()\n",
    "# model.load_weights(NameWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create the input for the model\n",
    "# val_inputs = imgs_to_windows(X_valid,400,patch_size,input_size)\n",
    "# print(val_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get the true value of the labels\n",
    "# Y_valid = gt_imgs_not_padded[N-N_valid:]\n",
    "# val_gt_patches = [img_crop(Y_valid[i], patch_size, patch_size) for i in range(N_valid)]\n",
    "# val_gt_patches =  np.asarray([val_gt_patches[i][j] for i in range(len(val_gt_patches)) for j in range(len(val_gt_patches[i]))])\n",
    "# val_true_labels = np.asarray([value_to_class(np.mean(val_gt_patches[i])) for i in range(len(val_gt_patches))])\n",
    "# print(val_true_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #predict\n",
    "# val_prediction = model.predict(val_inputs)\n",
    "# print(val_prediction[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute the metrics\n",
    "# from sklearn.metrics import f1_score\n",
    "# val_predicted_labels = ( (val_prediction < 0.5) * 1 ).flatten()\n",
    "# val_accuracy = np.sum(np.abs(val_predicted_labels - val_true_labels))/val_true_labels.shape[0]\n",
    "# print('Accuracy on validation set is: ', val_accuracy)\n",
    "# print('F1 score on validation set is:', f1_score(val_true_labels,val_predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images and pad them\n",
    "test_images = np.asarray(pick_test_images())\n",
    "\n",
    "test_images = padding_imgs(np.array(test_images),pad_size)\n",
    "\n",
    "test_images_not_padded = np.asarray(pick_test_images())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the input for the prediction\n",
    "test_inputs = imgs_to_windows(test_images,608,patch_size,input_size)\n",
    "print(test_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recover the model\n",
    "model, _,_ = create_model()\n",
    "model.load_weights(NameWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "test_prediction = model.predict(test_inputs)\n",
    "print(test_prediction[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted_labels = ( (test_prediction > 0.5) * 1 ).flatten()\n",
    "test_labels = test_predicted_labels.reshape(50,-1)\n",
    "print('Every row contains the labels of one image')\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the prediction on the image IDX\n",
    "IDX = 11\n",
    "im = label_to_img(608, 608, 16, 16, test_labels[IDX])\n",
    "plt.imshow(concatenate_images(test_images_not_padded[IDX], im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_masks_to_submission(SubmissionName, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
