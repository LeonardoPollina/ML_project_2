{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'py_files')\n",
    "\n",
    "def collect_train_test(pad_size, root_dir = \"../Data/training/\"):\n",
    "    ''' Load images and pad them using mirror boundary conditions\n",
    "    '''\n",
    "    # Load a set of image\n",
    "    image_dir = root_dir + \"images/\"\n",
    "    files = os.listdir(image_dir)\n",
    "    n = len(files) \n",
    "    print(\"Loading \" + str(n) + \" images\")\n",
    "    imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "\n",
    "    gt_dir = root_dir + \"groundtruth/\"\n",
    "    print(\"Loading \" + str(n) + \" groundtruth images\")\n",
    "    gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "\n",
    "    print('Padding images using pad of: ', pad_size)\n",
    "    imgs = padding_imgs(np.array(imgs),pad_size)\n",
    "    gt_imgs = padding_GT(np.array(gt_imgs),pad_size)\n",
    "    \n",
    "    print('Shape of imgs: ',imgs.shape)\n",
    "    print('Shape of gt_imgs: ',imgs.shape)\n",
    "    return imgs, gt_imgs\n",
    "\n",
    "def predict_on_test_and_save_prediction(root = '../Data'):\n",
    "    '''This function does the prediction, generate a submission file and saves the predicted images.\n",
    "        NOTE: works for a model with 2 neurons at the last layer'''\n",
    "    \n",
    "    print('Loading test images')\n",
    "    test_images = np.asarray(pick_test_images(root))\n",
    "    test_images = padding_imgs(np.array(test_images),pad_size)\n",
    "    \n",
    "    #prepare the input for the prediction\n",
    "    test_inputs = imgs_to_windows(test_images,608,patch_size,input_size)\n",
    "    print('Inputs for the test are ready. Shape: ', test_inputs.shape)\n",
    "    \n",
    "    print('Predicting... ')\n",
    "    #recover the model\n",
    "    model, _,_ = create_model()\n",
    "    model.load_weights(NameWeights)\n",
    "    test_prediction = model.predict(test_inputs)\n",
    "    print('Done!')\n",
    "    \n",
    "    print('Generating submission file...')\n",
    "    test_predicted_labels = ((test_prediction[:,0] < test_prediction[:,1]) * 1 ).flatten()\n",
    "    test_labels = test_predicted_labels.reshape(50,-1)\n",
    "    MY_masks_to_submission(SubmissionName, test_labels)\n",
    "    print('Submission saved in: ', SubmissionName)\n",
    "    \n",
    "    import pickle\n",
    "    # Saving the objects:\n",
    "    with open(PredictionName, 'wb') as f:\n",
    "        pickle.dump(test_predicted_labels, f)\n",
    "    print('Prediction saved in ', PredictionName)\n",
    "    \n",
    "    \n",
    "def train_f1_score():\n",
    "    #choose some images\n",
    "    IDX_VALID = np.random.randint(low=0, high=100, size = 4)\n",
    "    N_valid = IDX_VALID.shape[0]\n",
    "\n",
    "\n",
    "    #####################################################################\n",
    "    root_dir = '../Data/training/'\n",
    "    #Load, pad onnly imgs using the real pad_size\n",
    "    image_dir = root_dir + \"images/\"\n",
    "    files = os.listdir(image_dir)\n",
    "    n = len(files) \n",
    "    imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "    gt_dir = root_dir + \"groundtruth/\"\n",
    "    gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "    imgs = padding_imgs(np.array(imgs),pad_size)\n",
    "    gt_imgs = np.asarray(gt_imgs)\n",
    "\n",
    "\n",
    "    #Create X and Y validation\n",
    "    X_valid = imgs[IDX_VALID]\n",
    "    val_inputs = imgs_to_windows(X_valid,400,patch_size,input_size)\n",
    "\n",
    "    Y_valid = gt_imgs[IDX_VALID]\n",
    "    val_gt_patches = [img_crop(Y_valid[i], patch_size, patch_size) for i in range(N_valid)]\n",
    "    val_gt_patches =  np.asarray([val_gt_patches[i][j] for i in range(len(val_gt_patches)) for j in range(len(val_gt_patches[i]))])\n",
    "    val_true_labels = np.asarray([value_to_class(np.mean(val_gt_patches[i])) for i in range(len(val_gt_patches))])\n",
    "\n",
    "\n",
    "    #Predict\n",
    "    print('Predicting... ')\n",
    "    val_prediction = model.predict(val_inputs)\n",
    "    print('Done!')\n",
    "\n",
    "    #Compute accuracy and f1_Score\n",
    "    from sklearn.metrics import f1_score\n",
    "    val_predicted_labels = ((val_prediction[:,0] < val_prediction[:,1]) * 1 ).flatten()\n",
    "    val_accuracy = np.sum(np.abs(val_predicted_labels - val_true_labels))/val_true_labels.shape[0]\n",
    "    print('Accuracy on validation set is: ', 1 - val_accuracy)\n",
    "    print('F1 score on validation set is:', f1_score(val_true_labels,val_predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_5 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = collect_train_test(pad_rotate_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_test_and_save_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_5_bis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = collect_train_test(pad_rotate_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_test_and_save_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
